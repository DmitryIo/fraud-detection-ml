[2022-09-17 08:59:03,636] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: preprocessing_data.validate_model scheduled__2022-09-17T08:32:02.947415+00:00 [queued]>
[2022-09-17 08:59:03,643] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: preprocessing_data.validate_model scheduled__2022-09-17T08:32:02.947415+00:00 [queued]>
[2022-09-17 08:59:03,644] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-17 08:59:03,644] {taskinstance.py:1377} INFO - Starting attempt 1 of 2
[2022-09-17 08:59:03,644] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-17 08:59:03,661] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): validate_model> on 2022-09-17 08:32:02.947415+00:00
[2022-09-17 08:59:03,670] {standard_task_runner.py:52} INFO - Started process 18597 to run task
[2022-09-17 08:59:03,675] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'preprocessing_data', 'validate_model', 'scheduled__2022-09-17T08:32:02.947415+00:00', '--job-id', '409', '--raw', '--subdir', 'DAGS_FOLDER/model_dag.py', '--cfg-path', '/tmp/tmpw4sjwfu9', '--error-file', '/tmp/tmpnfq8qmip']
[2022-09-17 08:59:03,676] {standard_task_runner.py:80} INFO - Job 409: Subtask validate_model
[2022-09-17 08:59:03,752] {task_command.py:371} INFO - Running <TaskInstance: preprocessing_data.validate_model scheduled__2022-09-17T08:32:02.947415+00:00 [running]> on host rc1b-dataproc-m-xzxwmqcudfo0foh0.mdb.yandexcloud.net
[2022-09-17 08:59:03,832] {taskinstance.py:1589} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@example.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=preprocessing_data
AIRFLOW_CTX_TASK_ID=validate_model
AIRFLOW_CTX_EXECUTION_DATE=2022-09-17T08:32:02.947415+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-17T08:32:02.947415+00:00
[2022-09-17 08:59:24,490] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:24 INFO mlflow.spark: 'runs:/4f7f298745e14db8a77a101fc6ef26e0/model' resolved as 's3://otus-bigdata-dima-ioksha/1/4f7f298745e14db8a77a101fc6ef26e0/artifacts/model'
[2022-09-17 08:59:24,619] {credentials.py:1094} INFO - Found credentials in environment variables.
[2022-09-17 08:59:25,393] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:25 INFO mlflow.spark: URI 's3://otus-bigdata-dima-ioksha/1/4f7f298745e14db8a77a101fc6ef26e0/artifacts/model/sparkml' does not point to the current DFS.
[2022-09-17 08:59:25,394] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:25 INFO mlflow.spark: File 's3://otus-bigdata-dima-ioksha/1/4f7f298745e14db8a77a101fc6ef26e0/artifacts/model/sparkml' not found on DFS. Will attempt to upload the file.
[2022-09-17 08:59:26,408] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:26 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/21c8c05b-87b7-4b5e-b532-5e1f418d8cd0
[2022-09-17 08:59:39,911] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:39 INFO mlflow.spark: 'runs:/4f7f298745e14db8a77a101fc6ef26e0/pipeline' resolved as 's3://otus-bigdata-dima-ioksha/1/4f7f298745e14db8a77a101fc6ef26e0/artifacts/pipeline'
[2022-09-17 08:59:40,930] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:40 INFO mlflow.spark: URI 's3://otus-bigdata-dima-ioksha/1/4f7f298745e14db8a77a101fc6ef26e0/artifacts/pipeline/sparkml' does not point to the current DFS.
[2022-09-17 08:59:40,931] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:40 INFO mlflow.spark: File 's3://otus-bigdata-dima-ioksha/1/4f7f298745e14db8a77a101fc6ef26e0/artifacts/pipeline/sparkml' not found on DFS. Will attempt to upload the file.
[2022-09-17 08:59:41,950] {logging_mixin.py:115} WARNING - 2022/09/17 08:59:41 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/cedea168-b711-47e4-ac9e-2f3a3c80e532
[2022-09-17 09:00:40,131] {logging_mixin.py:115} INFO - 0         0
1         0
2         0
3         0
4         0
         ..
355095    0
355096    0
355097    0
355098    0
355099    0
Name: TX_FRAUD, Length: 355100, dtype: int32
[2022-09-17 09:00:40,132] {logging_mixin.py:115} INFO - 0         0.0
1         0.0
2         0.0
3         0.0
4         0.0
         ... 
355095    0.0
355096    0.0
355097    0.0
355098    0.0
355099    0.0
Name: prediction, Length: 355100, dtype: float64
[2022-09-17 09:00:40,132] {validate_model.py:43} INFO - y_test mean 0.07798085046465784
[2022-09-17 09:00:40,132] {validate_model.py:44} INFO - y_pred mean 0.0
[2022-09-17 09:03:08,925] {validate_model.py:53} INFO - POINT ESTIMATION OF F1 IS 0.0
[2022-09-17 09:03:09,632] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:09 INFO mlflow.spark: 'models:/fraud-transaction-predictor/Production' resolved as 's3://otus-bigdata-dima-ioksha/1/9dff32f633e04bafaa58b66628dcb5e6/artifacts/model'
[2022-09-17 09:03:10,345] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:10 INFO mlflow.spark: URI 's3://otus-bigdata-dima-ioksha/1/9dff32f633e04bafaa58b66628dcb5e6/artifacts/model/sparkml' does not point to the current DFS.
[2022-09-17 09:03:10,345] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:10 INFO mlflow.spark: File 's3://otus-bigdata-dima-ioksha/1/9dff32f633e04bafaa58b66628dcb5e6/artifacts/model/sparkml' not found on DFS. Will attempt to upload the file.
[2022-09-17 09:03:11,979] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:11 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/5c9cfc27-6d23-4b51-905f-fcbadc733574
[2022-09-17 09:03:13,625] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:13 INFO mlflow.spark: 'models:/fraud-transaction-pipeline/Production' resolved as 's3://otus-bigdata-dima-ioksha/1/9dff32f633e04bafaa58b66628dcb5e6/artifacts/pipeline'
[2022-09-17 09:03:14,337] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:14 INFO mlflow.spark: URI 's3://otus-bigdata-dima-ioksha/1/9dff32f633e04bafaa58b66628dcb5e6/artifacts/pipeline/sparkml' does not point to the current DFS.
[2022-09-17 09:03:14,337] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:14 INFO mlflow.spark: File 's3://otus-bigdata-dima-ioksha/1/9dff32f633e04bafaa58b66628dcb5e6/artifacts/pipeline/sparkml' not found on DFS. Will attempt to upload the file.
[2022-09-17 09:03:15,810] {logging_mixin.py:115} WARNING - 2022/09/17 09:03:15 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/46ccaded-38cc-4403-bbd4-e0acaa3b540c
[2022-09-17 09:03:44,490] {process_utils.py:125} INFO - Sending Signals.SIGTERM to group 18597. PIDs of all processes in the group: [18598, 18597]
[2022-09-17 09:03:44,490] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 18597
[2022-09-17 09:03:44,490] {taskinstance.py:1561} ERROR - Received SIGTERM. Terminating subprocesses.
[2022-09-17 09:03:45,080] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/ubuntu/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/ubuntu/fraud-detection-ml/utils/validate_model.py", line 96, in validate_model
    best_model_metric = _get_bootstraped_metric_for_model(best_model, transformed_test_df_best_model)
  File "/home/ubuntu/fraud-detection-ml/utils/validate_model.py", line 32, in _get_bootstraped_metric_for_model
    pandas_predictions = predictions.toPandas()
  File "/usr/lib/spark/python/pyspark/sql/pandas/conversion.py", line 138, in toPandas
    pdf = pd.DataFrame.from_records(self.collect(), columns=self.columns)
  File "/usr/lib/spark/python/pyspark/sql/dataframe.py", line 597, in collect
    return list(_load_from_socket(sock_info, BatchedSerializer(PickleSerializer())))
  File "/usr/lib/spark/python/pyspark/serializers.py", line 147, in load_stream
    yield self._read_with_length(stream)
  File "/usr/lib/spark/python/pyspark/serializers.py", line 172, in _read_with_length
    return self.loads(obj)
  File "/usr/lib/spark/python/pyspark/serializers.py", line 458, in loads
    return pickle.loads(obj, encoding=encoding)
  File "/usr/lib/spark/python/pyspark/sql/types.py", line 1415, in _create_row_inbound_converter
    return lambda *a: dataType.fromInternal(a)
  File "/home/ubuntu/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1563, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2022-09-17 09:03:45,083] {taskinstance.py:1415} INFO - Marking task as UP_FOR_RETRY. dag_id=preprocessing_data, task_id=validate_model, execution_date=20220917T083202, start_date=20220917T085903, end_date=20220917T090345
[2022-09-17 09:03:45,103] {standard_task_runner.py:92} ERROR - Failed to execute job 409 for task validate_model (Task received SIGTERM signal; 18597)
[2022-09-17 09:03:45,407] {process_utils.py:75} INFO - Process psutil.Process(pid=18598, status='terminated', started='08:59:03') (18598) terminated with exit code None
[2022-09-17 09:03:45,407] {process_utils.py:75} INFO - Process psutil.Process(pid=18597, status='terminated', exitcode=1, started='08:59:03') (18597) terminated with exit code 1
